## **一、需求起因**

在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。所以，就需要使用 redis 做一个缓冲操作，让请求先访问到 redis，而不是直接访问 MySQL 等数据库。

![](https://pic2.zhimg.com/v2-a5af5c1f96e94360e33720cf40037a49_b.jpg)![](https://pic2.zhimg.com/v2-a5af5c1f96e94360e33720cf40037a49_r.jpg)

这个业务场景，主要是解决读数据从 Redis 缓存，一般都是按照下图的流程来进行业务操作。

![](https://pic3.zhimg.com/v2-71df0305b4ff6ac7054d503e73657e76_b.jpg)![](https://pic3.zhimg.com/80/v2-71df0305b4ff6ac7054d503e73657e76_hd.jpg)

读取缓存步骤一般没有什么问题，但是一旦涉及到数据更新：数据库和缓存更新，就容易出现**缓存 (Redis) 和数据库（MySQL）间的数据一致性问题**。

不管是先写 MySQL 数据库，再删除 Redis 缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。举一个例子：

1\. 如果删除了缓存 Redis，还没有来得及写库 MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。

2\. 如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。

因为写和读是并发的，没法保证顺序, 就会出现缓存和数据库的数据不一致的问题。

如来解决？这里给出两个解决方案，先易后难，结合业务和技术代价选择使用。

## **二、缓存和数据库一致性解决方案**

![](https://pic1.zhimg.com/v2-e95fa019afd3535d9d61741472ec0e3c_b.jpg)![](https://pic1.zhimg.com/80/v2-e95fa019afd3535d9d61741472ec0e3c_hd.jpg)

**1\. 第一种方案：采用延时双删策略**

在写库前后都进行 redis.del(key) 操作，并且设定合理的超时时间。

伪代码如下：

```
public void write(String key,Object data){
 redis.delKey(key);
 db.updateData(data);
 Thread.sleep(500);
 redis.delKey(key);
 }

```

**具体的步骤就是：**

*   先删除缓存；
*   再写数据库；
*   休眠 500 毫秒；
*   再次删除缓存。

**那么，这个 500 毫秒怎么确定的，具体该休眠多久呢？**

需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

当然这种策略还要考虑 redis 和数据库主从同步的耗时。最后的的写数据的休眠时间：则在读数据业务逻辑的耗时基础上，加几百 ms 即可。比如：休眠 1 秒。

**设置缓存过期时间**

从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。

**该方案的弊端**

结合双删策略 + 缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。

**2、第二种方案：异步更新缓存 (基于订阅 binlog 的同步机制)**

**技术整体思路：**

MySQL binlog 增量订阅消费 + 消息队列 + 增量数据更新到 redis

*   **读 Redis**：热数据基本都在 Redis
*   **写 MySQL**: 增删改都是操作 MySQL
*   **更新 Redis 数据**：MySQ 的数据操作 binlog，来更新到 Redis

**Redis 更新**

**1）数据操作主要分为两大块：**

*   一个是全量 (将全部数据一次写入到 redis)
*   一个是增量（实时更新）

这里说的是增量, 指的是 mysql 的 update、insert、delate 变更数据。

**2）读取 binlog 后分析 ，利用消息队列, 推送更新各台的 redis 缓存数据。**

这样一旦 MySQL 中产生了新的写入、更新、删除等操作，就可以把 binlog 相关的消息推送至 Redis，Redis 再根据 binlog 中的记录，对 Redis 进行更新。

其实这种机制，很类似 MySQL 的主从备份机制，因为 MySQL 的主备也是通过 binlog 来实现的数据一致性。

这里可以结合使用 canal(阿里的一款开源框架)，通过该框架可以对 MySQL 的 binlog 进行订阅，而 canal 正是模仿了 mysql 的 slave 数据库的备份请求，使得 Redis 的数据更新达到了相同的效果。

当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ 等来实现推送更新 Redis。

以上就是 Redis 和 MySQL 数据一致性详解。

**觉得不错请点赞支持下。**

----end----

优知学院往期分享的 Redis 精选干货，感兴趣不妨深入了解，让你知其然更知其所以然，深度掌握 Redis。

[如何解决 Redis 雪崩、穿透、并发等 5 大难题](https://zhuanlan.zhihu.com/p/58331707)

[Redis 并发竞争 key 的解决方案详解](https://zhuanlan.zhihu.com/p/52756935)

[Redis 为什么是单线程，高并发快的 3 大原因详解](https://zhuanlan.zhihu.com/p/58038188)

[Redis 面试题目 49 道附答案](https://zhuanlan.zhihu.com/p/58333436)

写下你的评论...

双删还是没理解 一次两次有什么区别
确保更新之后也删了一次再拿到的就不是脏数据了，两次间隔内可能还有脏数据
再删第一次的时候新数据还没存入数据库，可能还有数据缓存到 Redis 所以更新数据库之后再删一次，是这个意思吗

双删的第一次应该要在 update 数据库的时候直接提交事务, 再 sleep, 再删一遍 redis 吧?

这个提交事务时间没有写出来的话, 可能会出现误导的

或者用一个新的线程 sleep500 毫秒后再删除一遍 redis

如果第二次删除的时候失败了怎么办？

第二种明显优于第一种，第一种你要休眠 500ms，严重影响性能

这个可以用新线程解决，就是双删写起来不太优雅
说实话 2 种策略都有问题🤨
双删不和单删一样吗？
应该是更新数据库成功之后 删除缓存，下一个读请求直接从数据库取然后放入缓存
各有优缺点，没有完美的
sleep 500 毫秒 你也不怕雪崩
写库后 sleep 没影响吧

这种情况，直接用 ehcache 不行吗?

我怎么在哪里看过这篇文章，请问是你们原创的嘛？？？
第一种明显不能用吧
第二种似乎也有问题啊🐔
双删感觉不太靠谱，楼主有 kafka 的方案吗
binlog 的方法真骚，不过简单点的话，是不是可以用加分布式锁的方式来同步缓存与数据库的一致操作，性能应该也还好，毕竟增删改的量级远远没有查询大

建议看看分布式事务，想当然得去设计方案实践时会有各种问题

概念讲解不清楚，业务场景介绍不清楚，解决方案解释不清楚，无深度只讲结论，典型培训风格。
两种都不太完美好么？第一种不用说了，第二种把缓存当数据库用，如果有些大表，一个表的数据你内存就可以爆了

第二种方案也保证不了一致性，你读到 binlog 去写 redis，那么这个时候就能保证一定写成功吗？失败了怎么处理？

补充两个使用设置超时时间来达到最终一致的方案。
方案 1.
1\. 设置缓存中待修改数据过期时间为 n 秒后，n 为写操作最大耗时
2\. 操作 db
3\. 删除缓存数据
方案 2
1\. 设置缓存过期中待修改数据过期时间为 n 秒后，且在此期间不使用缓存中数据
2\. 操作 db
3\. 删除缓存中数据
方案 2 可保证读取的数据是 db 中最新的，但是需对读逻辑做修改。
另外补充一点：实际情况中，查询 db 为空的记录也会缓存到缓存中，否则 db 可能会被查询为空的记录拖垮。
方案 1，如果缓存中不存在这条数据呢？这时候来一个查询的请求建立了缓存，并且它的处理时间比删除的线程长
1\. 缓存不存在，db 存在。缓存中增加一条数据，n 秒后过期。
2\. 缓存不存在，db 不存在。同 1，且标识该数据不存在